# MyDesign
MyDesign     
------------
##大环境
python==3.6  
numpy==1.19.3  
tensorflow==1.13  
cv2==3.4.1  
  
#总流程  
##前期
###信息的搜集与决断
对于各类技术的了解，以及准备采用何种技术，完成任务  
###数据的采样  
只做自己需要的数据集，并录入计算机  
###数据集模块化  
对数据集进行模块化处理，划分种类，打上标签等  
###构建网络模型  
利用深度学习的各类网络，搭建适用于项目的网络模型框架，用于训练  
###数据模型化
采用网络，对数据集进行训练，并生成model  
  
  
##后期  
###图像输入、预处理  
图像输入；预处理：主要包括二值化，噪声去除，倾斜较正等  
###二值化
使用图片，大多数是彩色图像，彩色图像所含信息量巨大，对于图片的内容，我们可以简单的分为前景与背景，为了让计算机更快的，更好的识别文字，我们需要先对彩色图进行处理，使图片只前景信息与背景信息，可以简单的定义前景信息为黑色，背景信息为白色，这就是二值化图了  
###噪声去除  
对于不同的文档，我们对噪声的定义可以不同，根据噪声的特征进行去噪，就叫做噪声去除  
###倾斜较正  
由于一般用户，在拍照文档时，都比较随意，因此拍照出来的图片不可避免的产生倾斜，这就需要文字识别软件进行较正  
###版面分析  
将文档图片分段落，分行的过程就叫做版面分析，由于实际文档的多样性，复杂性，因此，目前还没有一个固定的，最优的切割模型  
###字符切割   
由于拍照条件的限制，经常造成字符粘连，断笔，因此极大限制了识别系统的性能，这就需要文字识别软件有字符切割功能  
###字符识别  
利用已有模型对汉字进行匹配识别  
###版面恢复  
人们希望识别后的文字，仍然像原文档图片那样排列着，段落不变，位置不变，顺序不变地输出，这一过程就叫做版面恢复  
###后处理、校对  
对识别结果进行较正，就是后处理  

#交待  
##后台处理顺序 
**说明**  
1.DataSource.py……对图片集进行转换，并集成tfrecords文件保存，用于训练。  
2.DividePic.py……将图片对应标签，生成batch，为训练做好准备(对应汉字图片需要放到对应文件夹)  
3.CNNModel.py……建立网络模型((卷积+池化层）x2，全连接层x2，最后一个softmax层做分类,relu函数实现稀疏处理)  
4.TrainNet.py……进行训练并保存好模型  
5.FindRect.py(**尚缺**)……自然环境下环境恶劣，设置最终统一提交图片为白底黑字，供识别。  
    需要对上传的图片，首先做好预处理，寻找纸张的边缘，矩形的透视变换矫正。  
6.CharacterDivide.py(**效果不好**)……由于图片集皆是单字，这部分需要对一整页文字进行，分割、降噪等处理，并按古文本排列顺序保存好  
7.Test.py（**未加循环识别**）……用于测试效果，并且用于生成结果，目前是单字，后面要做的是，添加文件后触发5，然后循环识别文字，并将结果返回  
8.app.py……flask  
  
  
  
##前台
**说明**  
2选1，样式不同，但1较为完整，2懒得写显示页面，就直接搬的同学的模板，目前结果还未能显示，数据格式问题，可以换一种方式进行代入数据。  
1.ImgCV.html……上传图片，用于后台首先进行FindRect，然后文字分割，最后给Test识别  
2.index.html  
  
  
  
##文件夹
**说明**  
read……用于存放，文字分割好的单个文字  
static……css、js  
templates……静态页面  
test……存放自然环境拍摄的图片
train_00……处理好（规定格式命名，并存入tf文件的）的数据集图片、训练好的模型（checkpoint等）

##一些文件
requirements.txt  
definition.txt  设计对应  
train.tfrecords  
checkpoint  
events.out.tfevents.~  
thing.ckpt.data.~  
thing.ckpt.index  
thing.ckpt.meta  


最后更新时间：2020/12/18
--
